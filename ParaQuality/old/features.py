import math
from pyxdameraulevenshtein import normalized_damerau_levenshtein_distance

import editdistance
from pyentrp import entropy as ent

from utils.preprocess import tokenize, syllables, pos_tag
from utils.service import sentence2vec_client as sentence2vec
from utils.service.language_tool import SpellChecker
from utils.service.sts import StsSimilarity
from utils.service.word2vec_client import n_similarity, wm_distance


def exception_value(funct, value=0):
    def wrapper():
        try:
            funct()
        except:
            return value

    return wrapper


class FeatureFunction():
    @exception_value
    def extract(self, source, paraphrase, position):
        """
        :param position: the order of paraphrase
        :param source: original sentence
        :param paraphrase: the paraphrase generated by crowd
        :return: a value indicating the calculated feature
        """
        pass

    def explain(self, feature_value):
        """
        :param feature_value: 
        :return: A human readable text to explain why the given feature is not good enough; to 
                 explain how the source sentence can be improved by the worker 
        """
        pass


class WordsFF(FeatureFunction):
    def explain(self, feature_value):
        if feature_value < 0:
            return "The paraphrase is too 'shorter' than the original expression"
        else:
            return "The paraphrase is too 'longer' than the original expression"

    def extract(self, source, paraphrase, position):
        return len(tokenize(source)) - len(tokenize(paraphrase))


class LettersFF(FeatureFunction):
    def explain(self, feature_value):
        if feature_value < 0:
            return "The paraphrase is too 'shorter' than the original expression"
        else:
            return "The paraphrase is too 'longer' than the original expression"

    def extract(self, source, paraphrase, position):
        return len(source) - len(paraphrase)


class CommonWordsFF(FeatureFunction):
    def explain(self, feature_value):
        pass

    def extract(self, source, paraphrase, position):
        s = set(tokenize(source))
        p = set(tokenize(paraphrase))
        return 1 - len(p.difference(s)) / (len(p) + 1)


class SubstringFF(FeatureFunction):
    def explain(self, feature_value):
        pass

    def extract(self, source, paraphrase, position):
        if source.lower() in paraphrase.lower():
            return 1
        if paraphrase.lower() in source.lower():
            return -1
        return 0


class WordDifferenceEntropy(FeatureFunction):
    def explain(self, feature_value):
        pass

    def extract(self, source, paraphrase, position):
        s = set(tokenize(source))
        p = set(tokenize(paraphrase))
        return ent.shannon_entropy(" ".join(p.difference(s)))


class EntropyFF(FeatureFunction):
    def explain(self, feature_value):
        if feature_value < 0:
            return "The paraphrase is too 'shorter' than the original expression"
        else:
            return "The paraphrase is too 'longer' than the original expression"

    def extract(self, source, paraphrase, position):
        return ent.shannon_entropy(paraphrase)


class SemanticSimilarityFF(FeatureFunction):
    sts = StsSimilarity()

    def explain(self, feature_value):
        return "The paraphrase must be semantically equivalent to the original expression"

    def extract(self, source, paraphrase, position):
        return self.sts.similarity(source, paraphrase)


class Sentence2VecSimilarityFF(FeatureFunction):
    def explain(self, feature_value):
        return "The paraphrase must be semantically equivalent to the original expression"

    def extract(self, source, paraphrase, position):
        return sentence2vec.similarity(source, paraphrase)


class DifferenceSimilarityFF(FeatureFunction):
    def explain(self, feature_value):
        return "The paraphrase must be semantically equivalent to the original expression"

    def extract(self, source, paraphrase, position):
        s = set(tokenize(source))
        p = set(tokenize(paraphrase))

        p = p.difference(s)
        s = s.difference(p)

        return n_similarity(list(p), list(s))


class Word2VecSimilarityFF(FeatureFunction):
    def explain(self, feature_value):
        return "The paraphrase must be semantically equivalent to the original expression"

    def extract(self, source, paraphrase, position):
        return n_similarity(tokenize(source), tokenize(paraphrase))


class WMDistanceFF(FeatureFunction):
    def explain(self, feature_value):
        return "The paraphrase must be semantically equivalent to the original expression"

    def extract(self, source, paraphrase, position):
        wm = wm_distance(tokenize(source), tokenize(paraphrase))
        if math.isinf(wm):
            return 100
        return wm


class SpellingFF(FeatureFunction):
    spellcheker = SpellChecker()

    def explain(self, feature_value):
        if feature_value > 0:
            return "The paraphrase should not have spelling errors"
        return ""

    def extract(self, source, paraphrase, position):
        ss = self.spellcheker.check(source, ['TYPOS'], excludes_ids={'I_LOWERCASE'})
        ps = self.spellcheker.check(paraphrase, ['TYPOS'], excludes_ids={'I_LOWERCASE'})
        return len(ps) / (len(ss) + .1)


class GrammarFF(FeatureFunction):
    spellcheker = SpellChecker()

    def explain(self, feature_value):
        if feature_value > 0:
            return "The paraphrase should not have grammatical errors"
        return ""

    def extract(self, source, paraphrase, position):
        ss = self.spellcheker.check(source, ['GRAMMAR'])
        ps = self.spellcheker.check(paraphrase, ['GRAMMAR'])
        return len(ps) / (len(ss) + 1)


class CollocationFF(FeatureFunction):
    spellcheker = SpellChecker()

    def explain(self, feature_value):
        if feature_value > 0:
            return "Use correct collocations"
        return ""

    def extract(self, source, paraphrase, position):
        ss = self.spellcheker.check(source, ['COLLOCATIONS'])
        ps = self.spellcheker.check(paraphrase, ['COLLOCATIONS'])
        return len(ps) / (len(ss) + 1)


class ConfusedWordsFF(FeatureFunction):
    spellcheker = SpellChecker()

    def explain(self, feature_value):
        if feature_value > 0:
            return "The paraphrase has CONFUSED_WORDS"
        return ""

    def extract(self, source, paraphrase, position):
        ss = self.spellcheker.check(source, ['CONFUSED_WORDS'])
        ps = self.spellcheker.check(paraphrase, ['CONFUSED_WORDS'])
        return len(ps) / (len(ss) + 1)


class PunctuationFF(FeatureFunction):
    spellcheker = SpellChecker()

    def explain(self, feature_value):
        if feature_value > 0:
            return "The paraphrase has Punctuation errors"
        return ""

    def extract(self, source, paraphrase, position):
        ss = self.spellcheker.check(source, ['TYPOGRAPHY', 'PUNCTUATION'])
        ps = self.spellcheker.check(paraphrase, ['TYPOGRAPHY', 'PUNCTUATION'])
        return len(ps) / (len(ss) + 1)


class SemanticErrorFF(FeatureFunction):
    spellcheker = SpellChecker()

    def explain(self, feature_value):
        if feature_value > 0:
            return "The paraphrase has semantic errors"
        return ""

    def extract(self, source, paraphrase, position):
        ss = self.spellcheker.check(source, ['SEMANTICS'])
        ps = self.spellcheker.check(paraphrase, ['SEMANTICS'])
        return len(ps) / (len(ss) + 1)


class MiscErrorFF(FeatureFunction):
    spellcheker = SpellChecker()

    def explain(self, feature_value):
        if feature_value > 0:
            return "The paraphrase has semantic errors"
        return ""

    def extract(self, source, paraphrase, position):
        ss = self.spellcheker.check(source, ['STYLE', 'MISC'])
        ps = self.spellcheker.check(paraphrase, ['STYLE', 'MISC'])
        return len(ps) / (len(ss) + 1)


class NonStandardPhraseFF(FeatureFunction):
    spellcheker = SpellChecker()

    def explain(self, feature_value):
        if feature_value > 0:
            return "The paraphrase has NONSTANDARD_PHRASES"
        return ""

    def extract(self, source, paraphrase, position):
        ss = self.spellcheker.check(source, ['NONSTANDARD_PHRASES'])
        ps = self.spellcheker.check(paraphrase, ['NONSTANDARD_PHRASES'])
        return len(ps) / (len(ss) + 1)


class AutomatedReadabilityIndexFF(FeatureFunction):
    def explain(self, feature_value):
        pass

    @staticmethod
    def _measure(text):
        spaces = text.count(' ')
        chars = len(text) - spaces
        return 2.71 * chars / spaces + 0.5 * spaces / 1 - 21.43

    def extract(self, source, paraphrase, position):
        return GunningFogIndexFF._measure(paraphrase) / GunningFogIndexFF._measure(source)


class GunningFogIndexFF(FeatureFunction):
    def explain(self, feature_value):
        pass

    @staticmethod
    def _measure(text):
        words = tokenize(text)
        complex_words = [w for w in words if len(syllables(w)) >= 3]
        return 0.4 * (len(words) / 1 + 100 * len(complex_words) / (len(words) + 1))

    def extract(self, source, paraphrase, position):
        return GunningFogIndexFF._measure(paraphrase) / GunningFogIndexFF._measure(source)


class ColemanLiauIndexFF(FeatureFunction):
    def explain(self, feature_value):
        pass

    @staticmethod
    def _measure(text):
        S = 1
        L = len(text)
        return 0.0588 * L - 0.296 * S - 15.8

    def extract(self, source, paraphrase, position):
        return ColemanLiauIndexFF._measure(paraphrase) / ColemanLiauIndexFF._measure(source)


class FleschKincaidReadabilityFF(FeatureFunction):
    def explain(self, feature_value):
        pass

    @staticmethod
    def _measure(text):
        words = tokenize(text)
        sylabs = len([w for w in words if len(syllables(w)) > 2])
        words = len(words) + 1
        return 206.835 - 1.015 * words / 1 - 84.4 * sylabs / words

    def extract(self, source, paraphrase, position):
        return FleschKincaidReadabilityFF._measure(paraphrase) / FleschKincaidReadabilityFF._measure(source)


class SmogFF(FeatureFunction):
    def explain(self, feature_value):
        pass

    @staticmethod
    def _measure(text):
        words = tokenize(text)
        sylabs = len([w for w in words if len(syllables(w)) > 2])
        return 1.0430 * math.sqrt(sylabs * 30 / 1) + 3.1291

    def extract(self, source, paraphrase, position):
        return SmogFF._measure(paraphrase) / SmogFF._measure(source)


class LevenshteinFF(FeatureFunction):
    def explain(self, feature_value):
        pass

    def extract(self, source, paraphrase, position):
        # Levenshtein distance
        return editdistance.eval(source, paraphrase)


class NormalizedDamerauLevenshteinFF(FeatureFunction):
    def explain(self, feature_value):
        pass

    def extract(self, source, paraphrase, position):
        # Levenshtein distance
        return normalized_damerau_levenshtein_distance(source, paraphrase)


class WordLevelNormalizedDamerauLevenshteinFF(FeatureFunction):
    def explain(self, feature_value):
        pass

    def extract(self, source, paraphrase, position):
        # Levenshtein distance
        return normalized_damerau_levenshtein_distance(tokenize(source), tokenize(paraphrase))


class LongestCommonSubstringFF(FeatureFunction):
    @staticmethod
    def lcs(source, target):
        m = len(source)
        n = len(target)
        counter = [[0] * (n + 1) for x in range(m + 1)]
        longest = 0
        lcs_set = set()
        for i in range(m):
            for j in range(n):
                if source[i] == target[j]:
                    c = counter[i][j] + 1
                    counter[i + 1][j + 1] = c
                    if c > longest:
                        lcs_set = set()
                        longest = c
                        lcs_set.add(source[i - c + 1:i + 1])
                    elif c == longest:
                        lcs_set.add(source[i - c + 1:i + 1])

        return lcs_set

    def explain(self, feature_value):
        pass

    def extract(self, source, paraphrase, position):
        return len(LongestCommonSubstringFF.lcs(source, paraphrase))


class EditPositionFF(LongestCommonSubstringFF):
    def explain(self, feature_value):
        pass

    def extract(self, source, paraphrase, position):
        lcs = EditPositionFF.lcs(source, paraphrase)
        if lcs:
            lcs_1 = lcs.pop()
            edit_center = (paraphrase.index(lcs_1) + len(lcs_1)) / (2 * len(paraphrase) + 1)
            return edit_center

        return 0.5


class TenseFF(FeatureFunction):
    def explain(self, feature_value):
        pass

    """
    VB = 1
    VBG = 2
    VBN = 3
    VBZ = 4
    VBD = 5
    """

    @staticmethod
    def _pos_to_digit(pos):
        if pos == 'VB' or pos == 'VBP':
            return 1
        if pos == 'VBG':
            return 2
        if pos == 'VBN':
            return 3
        if pos == 'VBZ':
            return 4
        if pos == 'VBD':
            return 5

        return -1

    def extract(self, source, paraphrase, position):
        p = tokenize(paraphrase)
        tense = 0
        for t, tag in pos_tag(p):
            if 'VB' in tag:
                tense = max([tense, TenseFF._pos_to_digit(tag)])
        return tense


class PositionFF(FeatureFunction):
    def extract(self, source, paraphrase, position):
        return position


class OmniFeatureFunction(FeatureFunction):
    """
    This class is able to use all other feature functions 
    to generate features based on the source sentence and its paraphrase.
    """

    def __init__(self):
        self.extractors = [

            # Similarity Measures / LDA TOPIC Modeling
            SemanticSimilarityFF(),
            Word2VecSimilarityFF(),
            Sentence2VecSimilarityFF(),
            DifferenceSimilarityFF(),
            WMDistanceFF(),
            CommonWordsFF(),
            SubstringFF(),  # 7
            LevenshteinFF(),
            NormalizedDamerauLevenshteinFF(),
            WordLevelNormalizedDamerauLevenshteinFF(),
            LongestCommonSubstringFF(),
            EditPositionFF(),
            TenseFF(),
            # Informativeness
            # jargon
            WordsFF(),
            LettersFF(),
            EntropyFF(),
            WordDifferenceEntropy(),  # 17
            # Grammar
            SpellingFF(),
            GrammarFF(),
            CollocationFF(),  # 20
            ConfusedWordsFF(),  # 21
            PunctuationFF(),  # 22
            SemanticErrorFF(),  # 23
            MiscErrorFF(),
            NonStandardPhraseFF(),  # 25

            # Readability
            AutomatedReadabilityIndexFF(),
            GunningFogIndexFF(),
            ColemanLiauIndexFF(),
            FleschKincaidReadabilityFF(),
            SmogFF(),

            PositionFF()

            # Bias / Diversity
            # Missing Parameter
            # Jargon Distribution
        ]

        print("extractors:", self.extractors)

    def extract(self, source, paraphrase, position):
        ret = []
        for extractor in self.extractors:
            value = extractor.extract(source, paraphrase, position)
            ret.append(value)

        return ret

    def extract_as_map(self, source, paraphrase, position):
        ret = {}
        for extractor in self.extractors:
            value = extractor.extract(source, paraphrase, position)
            ret[extractor.__class__.__name__] = value

        return ret

    def explain(self, feature_values):
        pass

        # print(TenseFF().extract("", "suggest a seattle hotel room for 2 tomorrow"))
